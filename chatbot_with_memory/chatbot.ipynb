{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY']\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='llama3-8b-8192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Vaibhav! Nice to meet you! Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "res = model.invoke([HumanMessage(\"Hi!, i am vaibhav\")])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help! However, I'm a large language model, I don't have the ability to know your personal information, including your name. I'm designed to assist with general knowledge and language-related tasks, but I don't have access to personal data. If you'd like to share your name with me, I'd be happy to chat with you and get to know you better!\n"
     ]
    }
   ],
   "source": [
    "res = model.invoke([HumanMessage(\"what is my name?\")])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to our conversation, your name is Vaibhav!\n"
     ]
    }
   ],
   "source": [
    "# we need to pass entire conversation history to the model\n",
    "from langchain_core.messages import AIMessage\n",
    "res = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi!, i am vaibhav\"),\n",
    "        AIMessage(content=\"Hi vaibhav, how can i help you?\"),\n",
    "        HumanMessage(content=\"what is my name?\"),\n",
    "    ]\n",
    ")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message history \n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # conversation will store here \n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'123'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 2dc21d4e-df7c-4c0e-a274-0c3851f5bf21 not found for run 2913f8a2-709c-4c29-ad73-fb2c61387765. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi Vaibhav! Nice to meet you! What brings you here today? Do you have any questions or topics you'd like to discuss? I'm all ears!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi!, i am vaibhav\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 55c66328-87b8-4a9c-9fa7-0a428611aa21 not found for run 3588e59b-d93a-466f-b878-fec68b065333. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is still Vaibhav!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python code to generate a Fibonacci series:\n",
      "```\n",
      "def fibonacci(n):\n",
      "    a, b = 0, 1\n",
      "    result = []\n",
      "    for i in range(n):\n",
      "        result.append(a)\n",
      "        a, b = b, a + b\n",
      "    return result\n",
      "\n",
      "# Example usage:\n",
      "n = 10  # generate the first 10 Fibonacci numbers\n",
      "print(fibonacci(n))\n",
      "```\n",
      "This will output the first 10 Fibonacci numbers: `[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]`\n",
      "\n",
      "Here's a breakdown of how the code works:\n",
      "\n",
      "1. We define a function `fibonacci` that takes an integer `n` as input, which represents the number of Fibonacci numbers to generate.\n",
      "2. We initialize two variables `a` and `b` to 0 and 1, respectively, which are the first two Fibonacci numbers.\n",
      "3. We create an empty list `result` to store the Fibonacci numbers.\n",
      "4. We loop `n` times, and in each iteration:\n",
      "\t* We append the current value of `a` to the `result` list.\n",
      "\t* We update `a` and `b` by swapping their values and adding `a` to `b`. This is the recursive formula for Fibonacci numbers.\n",
      "5. Finally, we return the `result` list.\n",
      "\n",
      "You can also use a recursive function to generate the Fibonacci series:\n",
      "```\n",
      "def fibonacci(n):\n",
      "    if n <= 1:\n",
      "        return [0]\n",
      "    elif n == 2:\n",
      "        return [0, 1]\n",
      "    else:\n",
      "        fib = fibonacci(n-1)\n",
      "        fib.append(fib[-1] + fib[-2])\n",
      "        return fib\n",
      "\n",
      "print(fibonacci(10))  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "```\n",
      "This code uses a recursive function to generate the Fibonacci series, but it is less efficient than the iterative approach for large values of `n`."
     ]
    }
   ],
   "source": [
    "import time \n",
    "for chunk in model.stream([HumanMessage(\"write python code for fibonacci series\")]):\n",
    "    time.sleep(0.1)\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "x-beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
